2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Configure stats pid to 2276523
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Loading settings from /home/burning_event/wandb/settings
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-05-25 08:22:10,408 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': '/home/burning_event/train.py', 'program': 'train.py'}
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:_log_setup():520] Logging user logs to /home/burning_event/wandb/run-20240525_082210-lyj2u5uu/logs/debug.log
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:_log_setup():521] Logging internal logs to /home/burning_event/wandb/run-20240525_082210-lyj2u5uu/logs/debug-internal.log
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:init():560] calling init triggers
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:init():567] wandb.init called with sweep_config: {}
config: {'model_name': 'DANN', 'Domain': 'exp', 'source': 'JNU_0,JNU_2', 'target': 'CWRU_2', 'data_dir': '../burning_event/dataset', 'train_mode': 'source_combine', 'cuda_device': '0', 'save_dir': './ckpt', 'max_epoch': 50, 'batch_size': 32, 'num_workers': 0, 'signal_size': 2048, 'random_state': 927, 'project': 'experiment', 'fac': 0, 'adv': 1, 'recon': 0, 'iet': 0, 'normlizetype': 'mean-std', 'opt': 'adam', 'lr': 0.001, 'momentum': 0.9, 'betas': (0.9, 0.999), 'weight_decay': 0.001, 'lr_scheduler': 'stepLR', 'gamma': 0.2, 'steps': '20', 'tradeoff': ['exp', 'exp', 'exp'], 'dropout': 0.2, 'save': False, 'load_path': '', 'tsne': False}
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:init():610] starting backend
2024-05-25 08:22:10,409 INFO    MainThread:2276523 [wandb_init.py:init():614] setting up manager
2024-05-25 08:22:10,413 INFO    MainThread:2276523 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-05-25 08:22:10,413 INFO    MainThread:2276523 [wandb_init.py:init():622] backend started and connected
2024-05-25 08:22:10,417 INFO    MainThread:2276523 [wandb_init.py:init():711] updated telemetry
2024-05-25 08:22:10,428 INFO    MainThread:2276523 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-05-25 08:22:10,931 INFO    MainThread:2276523 [wandb_run.py:_on_init():2396] communicating current version
2024-05-25 08:22:10,971 INFO    MainThread:2276523 [wandb_run.py:_on_init():2405] got version response 
2024-05-25 08:22:10,971 INFO    MainThread:2276523 [wandb_init.py:init():795] starting run threads in backend
2024-05-25 08:22:11,114 INFO    MainThread:2276523 [wandb_run.py:_console_start():2374] atexit reg
2024-05-25 08:22:11,114 INFO    MainThread:2276523 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-05-25 08:22:11,114 INFO    MainThread:2276523 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-05-25 08:22:11,114 INFO    MainThread:2276523 [wandb_run.py:_redirect():2319] Redirects installed.
2024-05-25 08:22:11,115 INFO    MainThread:2276523 [wandb_init.py:init():838] run started, returning control to user process
2024-05-25 08:22:11,115 INFO    MainThread:2276523 [wandb_run.py:_config_callback():1376] config_cb None None {'model_name': 'DANN', 'Domain': 'exp', 'source': 'JNU_0,JNU_2', 'target': 'CWRU_2', 'data_dir': '../burning_event/dataset', 'train_mode': 'source_combine', 'cuda_device': '0', 'save_dir': './ckpt', 'max_epoch': 50, 'batch_size': 32, 'num_workers': 0, 'signal_size': 2048, 'random_state': 927, 'project': 'experiment', 'fac': 0, 'adv': 1, 'recon': 0, 'iet': 0, 'normlizetype': 'mean-std', 'opt': 'adam', 'lr': 0.001, 'momentum': 0.9, 'betas': [0.9, 0.999], 'weight_decay': 0.001, 'lr_scheduler': 'stepLR', 'gamma': 0.2, 'steps': '20', 'tradeoff': ['exp', 'exp', 'exp'], 'dropout': 0.2, 'save': False, 'load_path': '', 'tsne': False}
2024-05-25 08:22:27,335 WARNING MsgRouterThr:2276523 [router.py:message_loop():77] message_loop has been closed
